# -*- coding: utf-8 -*-
"""TASK2 GRIP

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hFOvFROrf1KBgn3jvu86xkLwUFFug7gE

# **SAAI SWETHA MK**

# Unsupervised Machine Learning - Iris dataset ( TASK2 )

### ***Importing Libraries***
"""

import pandas as pd
import matplotlib.pyplot as plt

"""### ***Reading the dataset***"""

data=pd.read_csv("/Iris.csv")

data.head(7)

data.describe()

data.hist()

data.plot(kind ="scatter", 
          x ='SepalLengthCm', 
          y ='PetalLengthCm')

"""### ***Elbow Method - To find optimum number of clusters***"""

iris_data = data.iloc[:, [ 1, 2, 3,4]].values

from sklearn.cluster import KMeans
wcss = []

for i in range(1, 11):
    kmeans = KMeans(n_clusters = i, init = 'k-means++', 
                    max_iter = 300, n_init = 10, random_state = 0)
    kmeans.fit(iris_data)
    wcss.append(kmeans.inertia_)

plt.plot(range(1, 11), wcss)
plt.title('The elbow method')
plt.xlabel('Number of clusters')
plt.ylabel('within cluster sum of sq') # Within cluster sum of squares
plt.show()

"""##### ***Insights : from the above graph between wscc and no.of clusters, we can infer that optimum number of clusters are 3***

###***Applying K-means with 3 clusters***
"""

model=KMeans(n_clusters = 3, init = 'k-means++', 
                    max_iter = 300, n_init = 10, random_state = 0)

predictions=model.fit_predict(data)

"""###***Visualising the clusters***"""

import matplotlib.pyplot as plt
import seaborn as sns

data["ratio"] = data["SepalLengthCm"]/data["SepalWidthCm"]

sns.lmplot(x="Id", y="ratio", data=data, hue="Species", fit_reg=False, legend=False)

plt.legend()
plt.show()
